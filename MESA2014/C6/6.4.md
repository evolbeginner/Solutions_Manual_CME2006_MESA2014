<p>
  <img src=img/6.4-P.png>
</p>

**Solution 1.**

This is an open question. Based on my limited experience, people would like to make a balance between leveraging prior knowledge and maintaining the integrity of the empirical evidence. Using a properly chosen prior could lead to more reasonable estimates, particularly when there is only limited data. But on the other side, we also hope to perform sensitivity analyses to ensure that the results are not too heavily affected by our prior beliefs and the extent to which the results are affected by different priors. By evaluating the posteriors under different priors, we can have a better idea of how robust the posterior is robust to the prior.


** Solution 2 (by Korbinian Strimmer).**

In my understanding, the answer to the open question is as follows.  

The key thing to understand is there is always prior information involved in any estimation procedure, either you specify it explicitly or it is implicit in the procedure. The second insight is that there are no neutral or uniformative priors.   Hence it is best to acknowledge that a prior is used, and then choose the one that has known properties and is minimally informative, rather than using the implicit prior that may have unknown properties that will potentially strongly bias your estimation. For example, maximum likelihood is equivalent to  assuming a flat prior and finding the maximum a-posteriori estimate.   However, this implicit prior is typically improper and is not protecting the model from overfitting, hence leading to poor estimates when sample size is small. The only case when you can ignore the prior is when the sample size is very large compared to the number of parameters in the model, because then the prior will have neglible influence on the estimate.
